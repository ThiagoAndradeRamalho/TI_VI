"""
An√°lise Acad√™mica Rigorosa para Determina√ß√£o de Pesos
====================================================

Este script implementa m√©todos estat√≠sticos para determinar pesos empiricamente
ao inv√©s de usar valores arbitr√°rios, seguindo padr√µes acad√™micos:

1. An√°lise de Componentes Principais (PCA) - Pesos emp√≠ricos
2. An√°lise de Correla√ß√£o - Valida√ß√£o de multicolinearidade  
3. An√°lise Fatorial - Estrutura latente das vari√°veis
4. Valida√ß√£o Estat√≠stica - Testes de adequa√ß√£o

Para RQ1 (Performance)
"""

import pandas as pd
import numpy as np
from sklearn.decomposition import PCA, FactorAnalysis
from sklearn.preprocessing import StandardScaler
from scipy.stats import pearsonr
import warnings
warnings.filterwarnings('ignore')

def load_and_prepare_data():
    """Carrega e prepara dados para an√°lise"""
    print("üìä Carregando dados para an√°lise acad√™mica...")
    
    # Carregar dados principais
    df_users = pd.read_csv('scripts/csv/users_metrics.csv')
    print(f"‚úÖ Carregados {len(df_users)} usu√°rios")
    
    # Remover valores ausentes e outliers extremos
    df_clean = df_users.dropna()
    
    # Log dos dados para reduzir impacto de outliers
    numeric_cols = df_users.select_dtypes(include=[np.number]).columns
    for col in numeric_cols:
        if (df_clean[col] > 0).all():  # S√≥ aplica log se todos valores > 0
            df_clean[f'{col}_log'] = np.log1p(df_clean[col])
    
    print(f"üìà Dataset limpo: {len(df_clean)} usu√°rios")
    return df_clean

def analyze_rq1_performance_weights(df):
    """
    RQ1: An√°lise acad√™mica de pesos para Performance Score
    """
    print("\n" + "="*60)
    print("üéØ RQ1: AN√ÅLISE ACAD√äMICA DE PERFORMANCE WEIGHTS")
    print("="*60)
    
    # Definir vari√°veis de performance
    performance_vars = [
        'pr_accept_rate',
        'prs_opened', 
        'commits_total',
        'activity_frequency'
    ]
    
    # Verificar disponibilidade das vari√°veis
    available_vars = [var for var in performance_vars if var in df.columns]
    print(f"üìã Vari√°veis dispon√≠veis: {available_vars}")
    
    if len(available_vars) < 2:
        print("‚ùå Insuficientes vari√°veis para an√°lise PCA")
        return None
    
    # Preparar dados para PCA
    X = df[available_vars].copy()
    
    # 1. AN√ÅLISE DE CORRELA√á√ÉO
    print("\nüìä 1. AN√ÅLISE DE CORRELA√á√ÉO")
    print("-" * 40)
    
    correlation_matrix = X.corr()
    print("Matriz de Correla√ß√£o:")
    print(correlation_matrix.round(3))
    
    # Teste de adequa√ß√£o KMO (Kaiser-Meyer-Olkin)
    def calculate_kmo(data):
        """Calcula KMO para adequa√ß√£o da an√°lise fatorial"""
        corr_matrix = data.corr()
        partial_corr = np.linalg.pinv(corr_matrix)
        partial_corr = -partial_corr / np.sqrt(np.outer(np.diag(partial_corr), np.diag(partial_corr)))
        np.fill_diagonal(partial_corr, 0)
        
        sum_sq_corr = np.sum(corr_matrix.values**2) - np.trace(corr_matrix.values**2)
        sum_sq_partial = np.sum(partial_corr**2)
        
        kmo = sum_sq_corr / (sum_sq_corr + sum_sq_partial)
        return kmo
    
    try:
        kmo_value = calculate_kmo(X)
        print(f"\nüîç KMO (adequa√ß√£o): {kmo_value:.3f}")
        if kmo_value > 0.6:
            print("‚úÖ KMO > 0.6: Adequado para an√°lise fatorial")
        else:
            print("‚ö†Ô∏è KMO < 0.6: An√°lise fatorial pode n√£o ser adequada")
    except:
        print("‚ö†Ô∏è N√£o foi poss√≠vel calcular KMO")
    
    # 2. AN√ÅLISE DE COMPONENTES PRINCIPAIS (PCA)
    print("\nüî¨ 2. AN√ÅLISE DE COMPONENTES PRINCIPAIS (PCA)")
    print("-" * 50)
    
    # Padronizar dados
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    # Executar PCA
    pca = PCA()
    pca.fit(X_scaled)
    
    # Vari√¢ncia explicada
    explained_var = pca.explained_variance_ratio_
    cumulative_var = np.cumsum(explained_var)
    
    print("Vari√¢ncia explicada por componente:")
    for i, (var, cum_var) in enumerate(zip(explained_var, cumulative_var)):
        print(f"  PC{i+1}: {var:.3f} ({var*100:.1f}%) - Acumulada: {cum_var:.3f} ({cum_var*100:.1f}%)")
    
    # Componentes (pesos)
    components = pca.components_
    print(f"\nüìä PESOS EMP√çRICOS (Primeiro Componente - {explained_var[0]*100:.1f}% da vari√¢ncia):")
    
    # Normalizar pesos para somar 1
    first_component = np.abs(components[0])  # Valores absolutos
    normalized_weights = first_component / first_component.sum()
    
    weights_dict = {}
    for var, weight in zip(available_vars, normalized_weights):
        weights_dict[var] = weight
        print(f"  ‚Ä¢ {var}: {weight:.3f} ({weight*100:.1f}%)")
    
    # 3. AN√ÅLISE FATORIAL
    print("\nüßÆ 3. AN√ÅLISE FATORIAL")
    print("-" * 30)
    
    try:
        # Determinar n√∫mero de fatores (crit√©rio Kaiser: eigenvalue > 1)
        eigenvalues = pca.explained_variance_
        n_factors = np.sum(eigenvalues > 1)
        print(f"Fatores com eigenvalue > 1: {n_factors}")
        
        if n_factors > 0:
            fa = FactorAnalysis(n_components=min(n_factors, len(available_vars)-1))
            fa.fit(X_scaled)
            
            loadings = fa.components_.T
            print("Cargas fatoriais:")
            for i, var in enumerate(available_vars):
                print(f"  ‚Ä¢ {var}: {loadings[i, 0]:.3f}")
    
    except Exception as e:
        print(f"‚ö†Ô∏è Erro na an√°lise fatorial: {e}")
    
    # 4. VALIDA√á√ÉO ESTAT√çSTICA
    print("\n‚úÖ 4. VALIDA√á√ÉO ESTAT√çSTICA")
    print("-" * 35)
    
    # Teste de esfericidade de Bartlett
    try:
        from scipy.stats import chi2
        n, p = X.shape
        corr_det = np.linalg.det(correlation_matrix)
        statistic = -((n - 1) - (2 * p + 5) / 6) * np.log(corr_det)
        p_value = 1 - chi2.cdf(statistic, p * (p - 1) / 2)
        
        print(f"Teste de Bartlett:")
        print(f"  Estat√≠stica: {statistic:.3f}")
        print(f"  p-valor: {p_value:.6f}")
        if p_value < 0.05:
            print("‚úÖ p < 0.05: Correla√ß√µes significativas (adequado para PCA)")
        else:
            print("‚ö†Ô∏è p > 0.05: Correla√ß√µes n√£o significativas")
    except:
        print("‚ö†Ô∏è N√£o foi poss√≠vel realizar teste de Bartlett")
    
    # 5. RECOMENDA√á√ÉO FINAL
    print("\nüí° 5. RECOMENDA√á√ÉO ACAD√äMICA PARA RQ1")
    print("-" * 45)
    
    if explained_var[0] > 0.5:  # Primeiro componente explica > 50%
        print("‚úÖ USAR PESOS EMP√çRICOS (PCA):")
        for var, weight in weights_dict.items():
            print(f"  ‚Ä¢ {var}: {weight:.3f}")
        print(f"\nJustificativa: Primeiro componente explica {explained_var[0]*100:.1f}% da vari√¢ncia")
    else:
        print("‚ö†Ô∏è USAR PESOS IGUAIS ou AN√ÅLISE INDIVIDUAL:")
        equal_weight = 1 / len(available_vars)
        for var in available_vars:
            print(f"  ‚Ä¢ {var}: {equal_weight:.3f}")
        print(f"Justificativa: Componentes n√£o concentram vari√¢ncia suficiente")
    
    return weights_dict

def generate_report():
    """Gera relat√≥rio acad√™mico completo"""
    print("\n" + "="*80)
    print("üìä RELAT√ìRIO ACAD√äMICO: DETERMINA√á√ÉO EMP√çRICA DE PESOS E VARI√ÅVEIS")
    print("="*80)
    
    # Carregar dados
    df = load_and_prepare_data()
    
    # An√°lise RQ1
    rq1_weights = analyze_rq1_performance_weights(df)
    
    # Relat√≥rio final
    print("\n" + "="*60)
    print("üìã RESUMO EXECUTIVO - METODOLOGIA ACADEMICAMENTE RIGOROSA")
    print("="*60)
    
    print("\nüéØ RQ1 (PERFORMANCE):")
    print("   M√©todo: An√°lise de Componentes Principais (PCA)")
    print("   Justificativa: Determina√ß√£o emp√≠rica de pesos baseada na vari√¢ncia explicada")
    if rq1_weights:
        print("   Pesos recomendados:")
        for var, weight in rq1_weights.items():
            print(f"     ‚Ä¢ {var}: {weight:.3f} ({weight*100:.1f}%)")
    
    return {
        'rq1_weights': rq1_weights,
    }

def main():
    """Execu√ß√£o principal"""
    print("üéì INICIANDO AN√ÅLISE ACAD√äMICA RIGOROSA")
    print("Determina√ß√£o emp√≠rica de pesos e vari√°veis dependentes")
    print("="*60)
    
    try:
        results = generate_report()
        
        # Salvar resultados
        import json
        with open('scripts/csv/weights_analysis.json', 'w') as f:
            json.dump({
                'rq1_weights': results['rq1_weights'],
                'methodology': 'PCA + Correlation Analysis',
                'timestamp': pd.Timestamp.now().isoformat()
            }, f, indent=2)
        
        print(f"\nüíæ Resultados salvos em: scripts/csv/weights_analysis.json")
        print("‚úÖ An√°lise acad√™mica conclu√≠da!")
        
    except Exception as e:
        print(f"‚ùå Erro na an√°lise: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()