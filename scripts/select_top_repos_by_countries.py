"""
Script de sele√ß√£o de reposit√≥rios populares do GitHub por pa√≠s.

Este script busca os 1500 reposit√≥rios mais populares do GitHub (por estrelas) e para cada
reposit√≥rio identifica o primeiro contribuidor que pertence a um dos pa√≠ses-alvo
(Brasil, √çndia, Alemanha ou Estados Unidos). A identifica√ß√£o √© feita atrav√©s da localiza√ß√£o
informada no perfil do GitHub de cada contribuidor.

Resultado: Gera o arquivo 'repos_final.csv' contendo os reposit√≥rios
selecionados e o primeiro usu√°rio de cada pa√≠s-alvo encontrado como contribuidor.
"""

import requests
import csv
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
import pycountry
from unidecode import unidecode
from token_loader import load_github_tokens

TOKENS = load_github_tokens()
NUM_WORKERS = len(TOKENS) * 8 if TOKENS else 1


def get_headers(token):
    return {'Authorization': f'token {token}'}


def round_robin_tokens():
    while True:
        for token in TOKENS:
            yield token


token_gen = round_robin_tokens()


def safe_request(url, params=None, max_retries=3):
    for attempt in range(max_retries):
        for _ in range(len(TOKENS)):
            token = next(token_gen)
            headers = get_headers(token)
            try:
                r = requests.get(url, headers=headers, params=params, timeout=30)
                if r.status_code == 403 and 'rate limit' in r.text.lower():
                    continue
                if r.status_code == 404:
                    # Usu√°rio n√£o encontrado (bots, contas deletadas, etc)
                    return None
                r.raise_for_status()
                return r
            except requests.exceptions.HTTPError as e:
                # Trata erros HTTP (404, 403, etc)
                if e.response.status_code == 404:
                    return None
                print(f"Erro HTTP (tentativa {attempt + 1}/{max_retries}): {e}")
                time.sleep(2)
                continue
            except (requests.exceptions.SSLError,
                    requests.exceptions.ConnectionError,
                    requests.exceptions.Timeout) as e:
                print(f"Erro de conex√£o (tentativa {attempt + 1}/{max_retries}): {e}")
                time.sleep(5)
                continue
        time.sleep(60)
    return None


def fetch_top_repos():
    """
    Busca os top 1500 reposit√≥rios do GitHub.
    Como a API limita a 1000 resultados por query, fazemos m√∫ltiplas queries
    com diferentes faixas de estrelas.
    """
    url = 'https://api.github.com/search/repositories'
    repos = []
    
    # Estrat√©gia: dividir em faixas de estrelas para evitar o limite de 1000 resultados
    # Primeira query: top 1000 (p√°ginas 1-10)
    print("Buscando top 1000 reposit√≥rios...")
    for page in range(1, 11):  # p√°ginas 1-10 = 1000 repos
        params = {
            'q': 'stars:>0',
            'sort': 'stars',
            'order': 'desc',
            'per_page': 100,
            'page': page
        }
        print(f"  Buscando p√°gina {page}/10...")
        r = safe_request(url, params)
        if r is None:
            print(f"  Erro ao buscar p√°gina {page}.")
            break
        data = r.json()
        if 'items' not in data:
            break
        repos.extend(data['items'])
        if len(data['items']) < 100:
            break
    
    print(f"Coletados {len(repos)} reposit√≥rios na primeira query.")
    
    # Se conseguimos os 1000, pegamos o n√∫mero de estrelas do √∫ltimo para usar como limite superior
    if len(repos) >= 1000:
        min_stars = repos[-1]['stargazers_count']
        print(f"Buscando mais 500 reposit√≥rios com at√© {min_stars} estrelas...")
        
        # Segunda query: pr√≥ximos 500 com estrelas <= ao √∫ltimo da primeira query
        for page in range(1, 6):  # p√°ginas 1-5 = 500 repos
            params = {
                'q': f'stars:<{min_stars}',
                'sort': 'stars',
                'order': 'desc',
                'per_page': 100,
                'page': page
            }
            print(f"  Buscando p√°gina {page}/5...")
            r = safe_request(url, params)
            if r is None:
                print(f"  Erro ao buscar p√°gina {page}.")
                break
            data = r.json()
            if 'items' not in data:
                break
            repos.extend(data['items'])
            if len(data['items']) < 100:
                break
    
    print(f"Total de reposit√≥rios encontrados: {len(repos)}")
    return repos


def fetch_contributors(owner, repo):
    contributors = []
    page = 1
    while True:
        url = f'https://api.github.com/repos/{owner}/{repo}/contributors'
        params = {'per_page': 100, 'page': page}
        r = safe_request(url, params)
        if r is None:
            break
        data = r.json()
        if not data or 'message' in data:
            break
        for user in data:
            if 'login' in user:
                contributors.append(user['login'])
        if len(data) < 100:
            break
        page += 1
    return contributors


def fetch_user(login):
    url = f'https://api.github.com/users/{login}'
    r = safe_request(url)
    if r is None:
        return login, '', ''
    data = r.json()
    location = data.get('location', '') or ''
    profile_url = data.get('html_url', '')
    return login, profile_url, location


# Pa√≠ses
country_names = {unidecode(c.name.lower()): c.name for c in pycountry.countries}
country_alpha2 = {c.alpha_2.lower(): c.name for c in pycountry.countries}
country_alpha3 = {c.alpha_3.lower(): c.name for c in pycountry.countries}
country_official = {unidecode(getattr(c, 'official_name', '').lower()): c.name for c in pycountry.countries if hasattr(c, 'official_name')}
country_all = {**country_names, **country_alpha2, **country_alpha3, **country_official}

# Principais cidades e estados dos 4 pa√≠ses
state_city_country = {
# Brasil
'sp': 'Brazil', 'sao paulo': 'Brazil', 'rj': 'Brazil', 'rio de janeiro': 'Brazil', 'mg': 'Brazil', 'minas gerais': 'Brazil',
'bh': 'Brazil', 'belo horizonte': 'Brazil',
'rs': 'Brazil', 'rio grande do sul': 'Brazil', 'pr': 'Brazil', 'parana': 'Brazil', 'sc': 'Brazil', 'santa catarina': 'Brazil',
'ba': 'Brazil', 'bahia': 'Brazil', 'ce': 'Brazil', 'ceara': 'Brazil', 'pe': 'Brazil', 'pernambuco': 'Brazil',
'recife': 'Brazil', 'porto alegre': 'Brazil', 'curitiba': 'Brazil', 'salvador': 'Brazil', 'fortaleza': 'Brazil',
'brasilia': 'Brazil', 'campo grande': 'Brazil', 'natal': 'Brazil', 'campinas': 'Brazil', 'sao jose do rio preto': 'Brazil',
'bauru': 'Brazil', 'maringa': 'Brazil', 'dourados': 'Brazil', 'teresina': 'Brazil', 'florianopolis': 'Brazil',
# √çndia
'delhi': 'India', 'new delhi': 'India', 'mumbai': 'India', 'maharashtra': 'India', 'bangalore': 'India', 'karnataka': 'India',
'chennai': 'India', 'tamil nadu': 'India', 'kolkata': 'India', 'west bengal': 'India', 'hyderabad': 'India', 'telangana': 'India',
'bengaluru': 'India', 'pune': 'India', 'ahmedabad': 'India', 'gujarat': 'India', 'kochi': 'India', 'kerala': 'India',
'noida': 'India', 'gurgaon': 'India', 'chandigarh': 'India', 'indore': 'India', 'nagpur': 'India', 'dehradun': 'India',
'mysore': 'India', 'kottayam': 'India', 'nanded': 'India', 'mangalore': 'India', 'bhopal': 'India', 'gandhinagar': 'India',
# Alemanha
'berlin': 'Germany', 'hamburg': 'Germany', 'munich': 'Germany', 'bavaria': 'Germany', 'frankfurt': 'Germany', 'hesse': 'Germany',
'stuttgart': 'Germany', 'baden-wurttemberg': 'Germany', 'dusseldorf': 'Germany', 'north rhine-westphalia': 'Germany',
'cologne': 'Germany', 'dresden': 'Germany', 'hannover': 'Germany', 'leipzig': 'Germany', 'darmstadt': 'Germany',
'karlsruhe': 'Germany', 'augsburg': 'Germany', 'magdeburg': 'Germany', 'muhltal': 'Germany', 'aachen': 'Germany',
'bonn': 'Germany', 'castrop-rauxel': 'Germany', 'deutschland': 'Germany', 'neustadt': 'Germany',
# Estados Unidos
'ny': 'United States', 'new york': 'United States', 'ca': 'United States', 'california': 'United States',
'tx': 'United States', 'texas': 'United States', 'fl': 'United States', 'florida': 'United States',
'il': 'United States', 'illinois': 'United States', 'wa': 'United States', 'washington': 'United States',
'los angeles': 'United States', 'san francisco': 'United States', 'chicago': 'United States', 'houston': 'United States',
'boston': 'United States', 'atlanta': 'United States', 'seattle': 'United States', 'miami': 'United States',
'dallas': 'United States', 'austin': 'United States', 'san diego': 'United States', 'philadelphia': 'United States',
'portland': 'United States', 'denver': 'United States', 'phoenix': 'United States', 'minneapolis': 'United States',
'oakland': 'United States', 'brooklyn': 'United States', 'manhattan': 'United States', 'bay area': 'United States',
'silicon valley': 'United States', 'palo alto': 'United States', 'mountain view': 'United States', 'sunnyvale': 'United States',
'san jose': 'United States', 'redmond': 'United States', 'menlo park': 'United States', 'berkeley': 'United States',
'pittsburgh': 'United States', 'cleveland': 'United States', 'detroit': 'United States', 'baltimore': 'United States',
}

country_aliases = {
'‰∏≠ÂõΩ': 'China', '‰∏≠Âúã': 'China', 'china': 'China',
'shanghai': 'China', 'beijing': 'China', 'bei jing': 'China', 'wuhan': 'China', 'wu han': 'China',
'shenzhen': 'China', 'guangzhou': 'China', 'chengdu': 'China', 'tianjin': 'China', 'hangzhou': 'China',
'mainland china': 'China', 'hong kong': 'Hong Kong', 'hk': 'Hong Kong', 'taipei': 'Taiwan', 'tapipei': 'Taiwan',
'taiwan': 'Taiwan', 'Âè∞ÁÅ£': 'Taiwan', 'Ëá∫ÁÅ£': 'Taiwan',
'deutschland': 'Germany', 'germany': 'Germany',
'nederland': 'Netherlands', 'holland': 'Netherlands',
'belgi√´': 'Belgium', 'belgique': 'Belgium', 'belgien': 'Belgium', 'belgium': 'Belgium',
'—Ä–æ—Å—Å–∏—è': 'Russia', 'russia': 'Russia',
'—É–∫—Ä–∞—ó–Ω–∞': 'Ukraine', 'ukraine': 'Ukraine',
'sverige': 'Sweden', 'sweden': 'Sweden',
'Êó•Êú¨': 'Japan', 'nippon': 'Japan', 'japan': 'Japan', 'tokyo': 'Japan',
'usa': 'United States', 'us': 'United States', 'united states': 'United States', 'united states of america': 'United States',
'brasil': 'Brazil', 'brazil': 'Brazil',
'france': 'France', 'francia': 'France', 'fran√ßa': 'France', 'paris': 'France',
'england': 'United Kingdom', 'uk': 'United Kingdom', 'united kingdom': 'United Kingdom', 'london': 'United Kingdom',
'turkey': 'Turkey', 't√ºrkiye': 'Turkey', 'turkiye': 'Turkey',
'canada': 'Canada', 'montreal': 'Canada', 'toronto': 'Canada', 'vancouver': 'Canada', 'ottawa': 'Canada',
'portugal': 'Portugal',
'italy': 'Italy', 'italia': 'Italy',
'spain': 'Spain', 'espa√±a': 'Spain', 'barcelona': 'Spain', 'galicia': 'Spain', 'bilbao': 'Spain',
'madrid': 'Spain', 'valencia': 'Spain', 'sevilla': 'Spain', 'zaragoza': 'Spain', 'malaga': 'Spain',
'india': 'India', 'bharat': 'India',
'iceland': 'Iceland', 'reykjavik': 'Iceland', 'reykjav√≠k': 'Iceland',
'poland': 'Poland', 'polska': 'Poland',
'australia': 'Australia',
'netherlands': 'Netherlands', 'amsterdam': 'Netherlands',
'denmark': 'Denmark', 'danmark': 'Denmark',
'norway': 'Norway', 'norge': 'Norway',
'switzerland': 'Switzerland', 'schweiz': 'Switzerland', 'suisse': 'Switzerland', 'svizzera': 'Switzerland',
'armenia': 'Armenia', 'yerevan': 'Armenia',
'greece': 'Greece', 'athens': 'Greece',
'czechoslovakia': 'Czechia', 'prague': 'Czechia',
}

TARGET_COUNTRIES = ['Brazil', 'India', 'Germany', 'United States']

INVALID_LOCATIONS = {
    'earth', 'world', 'internet', 'global', 'remote', 'worldwide', 'cyberspace',
    'milky way', 'universe', 'parallel universe', 'virtual', 'online', 'somewhere',
    'everywhere', 'nowhere', 'localhost', 'home', '127.0.0.1', 'cloud', 'web',
    'matrix', 'metaverse', 'cyber', 'digital', 'planet earth', 'terra', 'mundo',
    'n/a', 'none', 'unknown', 'undefined', 'null', 'secret', 'hidden', 'private',
    'your heart', 'your mind', 'your computer', 'your screen', 'behind you',
    'international', 'multinational', 'pan-european', 'european union', 'eu',
    'asia', 'europe', 'africa', 'south america', 'north america', 'oceania',
    'antarctica', 'arctic', 'atlantic', 'pacific', 'some', 'any', 'all',
    'galaxy', 'solar system', 'space', 'cosmos', 'void', 'limbo', 'purgatory',
    'heaven', 'hell', 'olympus', 'valhalla', 'asgard', 'narnia', 'wonderland',
    'neverland', 'atlantis', 'utopia', 'dystopia', 'middle earth', 'hogwarts',
    'wakanda', 'gotham', 'metropolis', 'pandora', 'tatooine', 'westeros',
    'in the', 'on the', 'at the', 'near the', 'from the', 'to the', 'building',
    'wandering', 'still', 'simulation', 'nomad', 'interstellar', 'dream', 'in a dream',
    'ponyville', 'equestria', 'wonkaville', 'mare tranquillitatis', 'in my room',
    'oasis', 'your dream', 'in your heart', 'javascript', 'typescript', 'python',
    'java', 'c++', 'rust', 'object location', 'bluelovers', 'the place', 'darkness',
    'evm', 'hbo', 'the grid', 'grid', 'now', 'kraftland', 'lenapehoking',
}

# Padr√µes sarc√°sticos que invalidam a localiza√ß√£o
SARCASTIC_PATTERNS = [';-)', ':)', ':-)', 'kidding', 'just kidding', 'lol', 'haha', 
                      'capital of tango', 'previously', 'tiny town']

# Nomes nativos de regi√µes que devem ser invalidados
NATIVE_REGION_NAMES = ['lenapehoking']

# Cidades escandinavas conhecidas
SCANDINAVIAN_CITIES = {
    'copenhagen': 'Denmark', 'k√∏benhavn': 'Denmark',
    'stockholm': 'Sweden',
    'oslo': 'Norway',
    'helsinki': 'Finland',
    'reykjavik': 'Iceland', 'reykjav√≠k': 'Iceland'
}

# Padr√µes t√©cnicos/programa√ß√£o que invalidam a localiza√ß√£o
TECH_PATTERNS = [
    'javascript', 'typescript', 'python', 'java', 'c++', 'rust', 'golang', 'ruby',
    'php', 'html', 'css', 'react', 'vue', 'angular', 'node', 'django', 'flask',
    '127.0.0.1', 'localhost', '/home/', '/usr/', 'http://', 'https://',
    '.com', '.org', '.net', '.io', 'github.com', 'gitlab.com',
]

# Emojis e s√≠mbolos que indicam localiza√ß√£o inv√°lida
INVALID_PATTERNS = ['üåç', 'üåé', 'üåè', 'üåê', 'üíª', 'üñ•Ô∏è', '‚å®Ô∏è', 'üöÄ', 'üõ∏', 'üëΩ', '‚ô•', '‚ù§Ô∏è', '‚ÆÄ']


def is_valid_location(location):
    """Verifica se a localiza√ß√£o √© v√°lida e n√£o √© amb√≠gua."""
    if not location or not location.strip():
        return False
    
    loc = location.strip().lower()
    loc_normalized = unidecode(loc)
    
    # Verifica se cont√©m emojis/s√≠mbolos inv√°lidos
    for pattern in INVALID_PATTERNS:
        if pattern in location:
            return False
    
    # Verifica se cont√©m padr√µes t√©cnicos
    for pattern in TECH_PATTERNS:
        if pattern in loc_normalized:
            return False
    
    # Verifica se a localiza√ß√£o inteira √© um termo inv√°lido
    if loc_normalized in INVALID_LOCATIONS:
        return False
    
    # Verifica se cont√©m termos inv√°lidos (pode ser parte de uma frase)
    words = set(loc_normalized.replace(',', ' ').replace(';', ' ').replace('/', ' ').split())
    if words & INVALID_LOCATIONS:
        return False
    
    # Descarta se cont√©m m√∫ltiplas cidades/pa√≠ses separados por "/" ou "‚ÆÄ"
    # mas permite "City, State" ou "City, Country" normais
    if '/' in location or '‚ÆÄ' in location:
        separators = ['/', '‚ÆÄ']
        for sep in separators:
            if sep in location:
                parts = location.split(sep)
                # Se tem mais de 2 partes, provavelmente √© m√∫ltiplas localiza√ß√µes
                if len(parts) > 2:
                    return False
    
    # Se tem apenas 1-2 caracteres e n√£o √© sigla de pa√≠s conhecida, descarta
    if len(loc_normalized) <= 2 and loc_normalized not in country_alpha2:
        return False
    
    # Descarta endere√ßos IP (formato xxx.xxx.xxx.xxx ou com porta)
    if ':' in loc_normalized and any(c.isdigit() for c in loc_normalized):
        return False
    
    # Descarta caminhos de sistema
    if loc_normalized.startswith('/') or loc_normalized.startswith('\\'):
        return False
    
    return True


def normalize_country_name(country):
    """Normaliza o nome do pa√≠s retornado por APIs ou aliases."""
    if not country:
        return ''
    ctry = unidecode(country.strip().lower())
    
    # Checa no alias primeiro
    if ctry in country_aliases:
        return country_aliases[ctry]
    
    # Checa por nome oficial, sigla, etc no pycountry
    for c in pycountry.countries:
        if ctry in [
            unidecode(c.name.lower()),
            unidecode(getattr(c, 'official_name', '').lower()),
            unidecode(getattr(c, 'common_name', '').lower()),
            unidecode(getattr(c, 'alpha_2', '').lower()),
            unidecode(getattr(c, 'alpha_3', '').lower())
        ]:
            return c.name
    
    # Checa se √© parte de uma string maior (ex: "belgique / belgien / belgium")
    for alias, norm in country_aliases.items():
        if alias in ctry:
            return norm
    
    # Se n√£o encontrou, retorna capitalizado
    return country.capitalize()


def validate_country_match(location, country):
    """
    Valida se o pa√≠s identificado realmente corresponde √† localiza√ß√£o.
    Evita falsos positivos onde uma cidade de um pa√≠s √© identificada como outro.
    """
    if not country or not location:
        return False
    
    loc_lower = unidecode(location.lower())
    
    # Lista de cidades chinesas que n√£o devem ser confundidas com outros pa√≠ses
    chinese_cities = ['shanghai', 'beijing', 'bei jing', 'wuhan', 'wu han', 'shenzhen', 
                      'guangzhou', 'chengdu', 'hangzhou', 'tianjin']
    
    # Se detectou China mas a localiza√ß√£o tem indica√ß√£o expl√≠cita de China
    if country == 'China':
        china_indicators = ['china', '‰∏≠ÂõΩ', '‰∏≠Âúã', 'mainland china', 'prc', 'shanghai', 
                           'beijing', 'wuhan', 'shenzhen']
        if any(ind in loc_lower for ind in china_indicators):
            return True
        # Se n√£o tem indicador de China e n√£o √© uma cidade chinesa conhecida, pode ser falso positivo
        if not any(city in loc_lower for city in chinese_cities):
            return False
    
    # Se √© Taiwan, valida
    if country == 'Taiwan':
        taiwan_indicators = ['taiwan', 'Âè∞ÁÅ£', 'Ëá∫ÁÅ£', 'taipei', 'tapipei']
        if any(ind in loc_lower for ind in taiwan_indicators):
            return True
        return False
    
    # Para pa√≠ses-alvo, sempre aceita se for identificado
    if country in TARGET_COUNTRIES:
        return True
    
    # Para outros pa√≠ses, rejeita se houver conflito
    return False


def identify_country(location):
    """
    Identifica o pa√≠s a partir de uma localiza√ß√£o com valida√ß√µes robustas.
    Retorna string vazia se a localiza√ß√£o for inv√°lida ou amb√≠gua.
    """
    if not location or not is_valid_location(location):
        return ''
    
    loc = unidecode(location.strip().lower())
    original_location = location.strip()
    
    # VALIDA√á√ÉO 1: Rejeita localiza√ß√µes sarc√°sticas ou piadas
    for pattern in SARCASTIC_PATTERNS:
        if pattern in loc:
            return ''
    
    # VALIDA√á√ÉO 2: Rejeita nomes nativos de regi√µes
    for native_name in NATIVE_REGION_NAMES:
        if native_name in loc:
            return ''
    
    # VALIDA√á√ÉO 3: Detecta men√ß√µes expl√≠citas de "China" no texto
    # Casos como "City of Science which may or may not in China" devem retornar China
    china_patterns = ['in china', 'china.', 'china,', ' china ', 'mainland china', 'prc']
    for pattern in china_patterns:
        if pattern in loc:
            return 'China'
    
    # VALIDA√á√ÉO 4: Detecta cidades espanholas conhecidas
    spanish_cities = ['bilbao', 'barcelona', 'madrid', 'valencia', 'sevilla', 'zaragoza', 'malaga']
    for city in spanish_cities:
        if city in loc:
            # Verifica se n√£o √© uma localiza√ß√£o m√∫ltipla amb√≠gua
            if '-' in original_location or '/' in original_location:
                # Se tem separador, s√≥ retorna Espanha se n√£o mencionar outro pa√≠s
                parts = original_location.replace('-', '/').split('/')
                country_mentions = []
                for part in parts:
                    part_lower = unidecode(part.strip().lower())
                    if part_lower in country_aliases:
                        country_mentions.append(country_aliases[part_lower])
                # Se mencionou m√∫ltiplos pa√≠ses, retorna vazio (amb√≠guo)
                if len(country_mentions) > 1:
                    return ''
            return 'Spain'
    
    # VALIDA√á√ÉO 5: Detecta cidades islandesas
    icelandic_cities = ['reykjavik', 'reykjav√≠k']
    for city in icelandic_cities:
        if city in loc:
            # Similar √† l√≥gica de cidades espanholas
            if '-' in original_location or '/' in original_location:
                parts = original_location.replace('-', '/').split('/')
                country_mentions = []
                for part in parts:
                    part_lower = unidecode(part.strip().lower())
                    if part_lower in country_aliases:
                        country_mentions.append(country_aliases[part_lower])
                if len(country_mentions) > 1:
                    return ''
            return 'Iceland'
    
    # VALIDA√á√ÉO 6: Valida endere√ßos chineses completos (Shaanxi Province, China)
    if 'province' in loc and 'china' in loc:
        return 'China'
    if 'district' in loc and 'china' in loc:
        return 'China'
    
    # VALIDA√á√ÉO 7: Montreal sempre √© no Canad√°
    if 'montreal' in loc:
        return 'Canada'
    
    # VALIDA√á√ÉO 8: Detecta cidades escandinavas
    for city, country in SCANDINAVIAN_CITIES.items():
        if city in loc:
            # Se menciona m√∫ltiplos pa√≠ses, retorna vazio
            if '-' in original_location or '/' in original_location:
                parts = original_location.replace('-', '/').split('/')
                country_mentions = []
                for part in parts:
                    part_lower = unidecode(part.strip().lower())
                    if part_lower in country_aliases:
                        country_mentions.append(country_aliases[part_lower])
                if len(country_mentions) > 1:
                    return ''
            # Retorna apenas se for pa√≠s-alvo
            if country in TARGET_COUNTRIES:
                return country
            # Se n√£o √© pa√≠s-alvo, retorna vazio (n√£o nos interessa)
            return ''
    
    # VALIDA√á√ÉO 9: Remove separadores problem√°ticos e pega apenas a parte mais relevante
    if '/' in location or '‚ÆÄ' in location:
        for sep in ['/', '‚ÆÄ']:
            if sep in location:
                parts = [p.strip() for p in location.split(sep)]
                # Filtra partes vazias ou inv√°lidas
                valid_parts_temp = [p for p in parts if p and is_valid_location(p)]
                if valid_parts_temp:
                    # Tenta a √∫ltima parte primeiro (geralmente a mais espec√≠fica)
                    for part in reversed(valid_parts_temp):
                        part_loc = unidecode(part.strip().lower())
                        # Checa se √© cidade/pa√≠s conhecido
                        if part_loc in country_aliases:
                            return country_aliases[part_loc]
                        if part_loc in state_city_country:
                            return state_city_country[part_loc]
                    # Se nenhuma parte foi reconhecida, continua com o fluxo normal
                    location = valid_parts_temp[-1]
                    loc = unidecode(location.strip().lower())
    
    # VALIDA√á√ÉO 10: Verifica aliases de pa√≠ses primeiro
    if loc in country_aliases:
        return country_aliases[loc]
    
    # VALIDA√á√ÉO 11: Separa por v√≠rgula (formato comum: "City, Country")
    parts = [p.strip() for p in loc.replace(';', ',').replace('|', ',').split(',') if p.strip()]
    
    # Filtra partes inv√°lidas
    valid_parts = [p for p in parts if is_valid_location(p)]
    if not valid_parts:
        return ''
    
    # VALIDA√á√ÉO 12: Verifica cada parte nos dicion√°rios (prioriza √∫ltima parte = pa√≠s)
    for part in reversed(valid_parts):
        if part in country_aliases:
            return country_aliases[part]
        if part in state_city_country:
            return state_city_country[part]
        if part in country_all:
            return country_all[part]
    
    # VALIDA√á√ÉO 13: Tenta API Nominatim apenas se tem 2+ partes v√°lidas
    if len(valid_parts) > 1:
        try:
            resp = requests.get(
                'https://nominatim.openstreetmap.org/search',
                params={'q': location, 'format': 'json', 'addressdetails': 1, 'limit': 1},
                headers={'User-Agent': 'github-country-lookup'},
                timeout=10
            )
            if resp.status_code == 200:
                data = resp.json()
                if data and 'address' in data[0]:
                    addr = data[0]['address']
                    if 'country' in addr:
                        country_found = addr['country']
                        # Normaliza e valida se est√° nos pa√≠ses-alvo
                        normalized = normalize_country_name(country_found)
                        if normalized in TARGET_COUNTRIES:
                            return normalized
        except Exception:
            pass
    
    # VALIDA√á√ÉO 14: Se tem 1 palavra, tenta como pa√≠s
    if len(valid_parts) == 1:
        part = valid_parts[0]
        if part in country_all:
            return country_all[part]
        if part in state_city_country:
            return state_city_country[part]
    
    # VALIDA√á√ÉO 15: Busca por cidades/estados conhecidos APENAS se n√£o mencionou China
    # Evita que cidades brasileiras sejam detectadas quando h√° men√ß√£o √† China
    if 'china' not in loc and '‰∏≠ÂõΩ' not in original_location and '‰∏≠Âúã' not in original_location:
        for key, country in state_city_country.items():
            if key in loc:
                return country
    
    return ''


def main():
    repos = fetch_top_repos()
    print(f"Buscando contribuidores dos {len(repos)} reposit√≥rios...")
    rows = []
    repo_count = 0
    
    with ThreadPoolExecutor(max_workers=NUM_WORKERS) as executor:
        for repo in repos:
            repo_count += 1
            owner = repo['owner']['login']
            name = repo['name']
            repo_id = repo['id']
            repo_url = repo['html_url']
            
            print(f"[{repo_count}/{len(repos)}] Processando: {name}...")
            contributors = fetch_contributors(owner, name)
            
            if not contributors:
                print(f"  ‚ö†Ô∏è  Nenhum contribuidor encontrado")
                continue
            
            found = False
            future_to_login = {executor.submit(fetch_user, login): login for login in contributors}
            
            for future in as_completed(future_to_login):
                try:
                    login, profile_url, location = future.result()
                    
                    # Pula se n√£o conseguiu buscar o usu√°rio
                    if not profile_url:
                        continue
                    
                    # Pula se a localiza√ß√£o √© inv√°lida ou amb√≠gua
                    if not is_valid_location(location):
                        print(f"  ‚ö†Ô∏è  Localiza√ß√£o inv√°lida/amb√≠gua para {login}: '{location}'")
                        continue
                    
                    country = identify_country(location)
                    
                    # Pula se n√£o conseguiu identificar o pa√≠s
                    if not country:
                        print(f"  ‚ö†Ô∏è  Pa√≠s n√£o identificado para {login}: '{location}'")
                        continue
                    
                    country = normalize_country_name(country)
                    
                    # Valida se o pa√≠s identificado realmente corresponde √† localiza√ß√£o
                    if not validate_country_match(location, country):
                        print(f"  ‚ö†Ô∏è  Pa√≠s '{country}' n√£o corresponde √† localiza√ß√£o '{location}' para {login}")
                        continue
                    
                    if country in TARGET_COUNTRIES:
                        rows.append([name, repo_id, repo_url, login, profile_url, location, country])
                        print(f"  ‚úÖ Encontrado: {login} ({country})")
                        found = True
                        break  # S√≥ salva o primeiro!
                except Exception as e:
                    print(f"  ‚ö†Ô∏è  Erro ao processar usu√°rio: {e}")
                    continue
            
            if found:
                # Salva progresso a cada repo encontrado
                with open('repos_final.csv', 'w', newline='', encoding='utf-8') as f:
                    writer = csv.writer(f)
                    writer.writerow(['repo_name', 'repo_id', 'repo_url', 'login', 'profile_url', 'location', 'country'])
                    for row in rows:
                        writer.writerow(row)
            
    print(f"\n‚úÖ Conclu√≠do! Total de reposit√≥rios com pa√≠s-alvo: {len(rows)}")
    print("Salvando no CSV final...")
    with open('repos_final.csv', 'w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        writer.writerow(['repo_name', 'repo_id', 'repo_url', 'login', 'profile_url', 'location', 'country'])
        for row in rows:
            writer.writerow(row)


if __name__ == '__main__':
    main()